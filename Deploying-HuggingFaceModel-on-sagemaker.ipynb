{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc4d3b7-0103-4f04-adea-aee8141e0f8b",
   "metadata": {},
   "source": [
    "## Mordenizing ML Workloads with AWS Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20613887-1161-4c2b-836c-16e9b54cf2f9",
   "metadata": {},
   "source": [
    "### Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a995e6dd-5e47-413d-8a12-1ce5bdb92f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch scipy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa59978-8c82-4bcf-b60b-8c666021c5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.utils import name_from_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78223f-4b0e-406b-b852-4a201c3014bb",
   "metadata": {},
   "source": [
    "### Load Model and tokenizer from pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6bba33-b673-4de6-8aa4-d357b0bc9d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build tokenizer and model from pretrained weights\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"model/tokenizer\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c3c63-d844-41d3-8b9c-d3604edecc71",
   "metadata": {},
   "source": [
    "### Create a model.tar.gz file to be used by SageMaker endpoint \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65df6f24-87ee-4aca-a8ae-8e14b8c9dea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Github/model\n"
     ]
    }
   ],
   "source": [
    "# change directory\n",
    "%cd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8510e8cb-db5b-42a3-8aa7-7dce7ea86e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json  pytorch_model.bin\ttokenizer\n"
     ]
    }
   ],
   "source": [
    "# model folder has model.bin & config.json files for the model and a tokenizer folder with tokenizer files\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61e40946-9278-4bcd-ba1d-3ceb56358681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "pytorch_model.bin\n",
      "tokenizer/\n",
      "tokenizer/tokenizer.json\n",
      "tokenizer/config.json\n",
      "tokenizer/vocab.json\n",
      "tokenizer/special_tokens_map.json\n",
      "tokenizer/tokenizer_config.json\n",
      "tokenizer/merges.txt\n",
      "tokenizer/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65fdc46d-8ac3-4f92-856e-9be451e2a8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json  model.tar.gz  pytorch_model.bin  tokenizer\n"
     ]
    }
   ],
   "source": [
    "# model.tar.gz is created with above directory structure\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe463413-0c98-4d94-8f46-b16945d1c644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Github\n"
     ]
    }
   ],
   "source": [
    "# change the directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6705e-44f1-4990-b855-3a209e366eba",
   "metadata": {},
   "source": [
    "### Upload the model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940ffd0f-c936-4b68-bf34-4b44ca2db5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload model to S3\n",
    "role = sagemaker.get_execution_role()\n",
    "sess=sagemaker.Session()\n",
    "region=sess.boto_region_name\n",
    "bucket=sess.default_bucket()\n",
    "sm_client=boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb5b40e-910f-4b82-a97e-3b647f24897e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded model to S3:\n",
      "s3://sagemaker-ap-south-1-128015641074/locobuzzmodel/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_key = '{}/model/model.tar.gz'.format('locobuzzmodel')\n",
    "model_path = 's3://{}/{}'.format(bucket, model_key)\n",
    "boto3.resource('s3').Bucket(bucket).upload_file('model/model.tar.gz', model_key)\n",
    "print(\"Uploaded model to S3:\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8ebed-cb3e-4ff3-866f-0978412d2eb7",
   "metadata": {},
   "source": [
    "### Define a HuggingFace model and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "957105ee-148d-4749-b506-507d268519c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import json\n",
      "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
      "import numpy\n",
      "from scipy.special import softmax\n",
      "\n",
      "def allot(prediction):\n",
      "    x = prediction.index(max(prediction))\n",
      "    if x == 0:\n",
      "        return \"negative\"\n",
      "    elif x == 1:\n",
      "        return \"neutral\"\n",
      "    elif x == 2:\n",
      "        return \"positive\"\n",
      "    else:\n",
      "        return \"unknown\"\n",
      "\n",
      "def model_fn(model_dir):\n",
      "    \"\"\"\n",
      "    Load the model for inference\n",
      "    \"\"\"\n",
      "    model_path = os.path.join(model_dir, 'tokenizer/')\n",
      "\n",
      "    # Load BERT tokenizer from disk.\n",
      "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
      "\n",
      "    # Load BERT model from disk.\n",
      "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
      "    \n",
      "    model_dict = {'model': model, 'tokenizer':tokenizer}\n",
      "    return model_dict\n",
      "\n",
      "def predict_fn(input_data, model):\n",
      "    \"\"\"\n",
      "    Apply model to the incoming request\n",
      "    \"\"\"\n",
      "\n",
      "    tokenizer = model['tokenizer']\n",
      "    bert_model = model['model']\n",
      "    \n",
      "\n",
      "    encoded_input = tokenizer(input_data, truncation = True, max_length = 500, return_tensors='pt')\n",
      "\n",
      "    result = bert_model(**encoded_input)\n",
      "\n",
      "    # post processing of the result\n",
      "    scores = result[0][0].detach().numpy()\n",
      "    scores_final = softmax(scores)\n",
      "    scores_final = list(scores_final)\n",
      "    result = allot(scores_final)\n",
      "    final = {\n",
      "        \"result\": result,\n",
      "        \"scores\": scores_final\n",
      "    }\n",
      "    return final\n",
      "\n",
      "def input_fn(request_body, request_content_type):\n",
      "    \"\"\"\n",
      "    Deserialize and prepare the prediction input\n",
      "    \"\"\"\n",
      "\n",
      "    if request_content_type == \"application/json\":\n",
      "        request = json.loads(request_body)\n",
      "\n",
      "    else:\n",
      "        request = request_body\n",
      "        \n",
      "    return request[\"inputs\"] \n",
      "\n",
      "def output_fn(prediction, response_content_type):\n",
      "    \"\"\"\n",
      "    Serialize and prepare the prediction output\n",
      "    \"\"\"\n",
      "    \n",
      "    #float32 to float conversion\n",
      "    prediction[\"scores\"] = [float(score) for score in prediction[\"scores\"]]\n",
      "    \n",
      "    if response_content_type == \"application/json\":\n",
      "        response = json.dumps(prediction)\n",
      "        \n",
      "    else:\n",
      "        response = json.dumps(prediction)\n",
      "\n",
      "    return response"
     ]
    }
   ],
   "source": [
    "# define an inference.py file in the code folder\n",
    "%cat code/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bbf6ac6-7d8c-4c86-8669-aae7c6bf6f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "hub = {\n",
    "    'HF_TASK':'text-classification'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env = hub,\n",
    "   model_data=model_path,  # path to your trained sagemaker model\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.26\", # transformers version used\n",
    "   pytorch_version='1.13', # Pytorch version used\n",
    "   py_version=\"py39\", # python version of the DLC\n",
    "   entry_point =\"code/inference.py\" # path to the inference.py file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d42749ea-e867-4c5d-ad6c-ab66d9bc306d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---!CPU times: user 35.9 s, sys: 4.24 s, total: 40.1 s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244e11e-783c-459f-a7e6-8562554663f1",
   "metadata": {},
   "source": [
    "### Testing the deployed Model for real time inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f8325da-1679-4b83-9d1b-a2c04415f123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.4 ms, sys: 0 ns, total: 4.4 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = {\n",
    "\"inputs\": \"Sagemaker makes machine learning very efficient.\"\n",
    "}\n",
    "\n",
    "output = predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "821932b2-c1b4-4a75-a712-0446d5661e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'result': 'positive', 'scores': [0.0016569155268371105, 0.11447102576494217, 0.8838720917701721]}\n"
     ]
    }
   ],
   "source": [
    "print(type(output))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14575dee-a453-4b9f-b1ac-d593997bc0b2",
   "metadata": {},
   "source": [
    "### Testing for real time inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38e7dcf6-01b1-4f3f-b5d2-a95c98d27500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'positive',\n",
       " 'scores': [0.000438973045675084, 0.000360532954800874, 0.9992005228996277]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "endpoint_name = predictor.endpoint_name\n",
    "\n",
    "data = {\n",
    "    \"inputs\": \"This is very good product, comes with great packaging as well\"\n",
    "}\n",
    "\n",
    "# Create a SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Convert the data dictionary to JSON\n",
    "payload = json.dumps(data)\n",
    "\n",
    "\n",
    "# Invoke the SageMaker endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "result = response[\"Body\"].read().decode(\"utf-8\")\n",
    "final_result = json.loads(result)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7bc9c-a1fa-4a40-830a-741fa3f48e9f",
   "metadata": {},
   "source": [
    "### Deleting the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20babcb0-a495-4d07-bbd1-b26c7e8b669d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1a2b6-b922-4e65-a70c-ec0f5da92654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
